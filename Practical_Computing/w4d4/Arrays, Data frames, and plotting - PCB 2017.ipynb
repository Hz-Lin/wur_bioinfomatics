{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: Steelblue\"> Arrays, dataframes, and plotting </span>\n",
    "## <span style=\"color: Steelblue\"> A short primer on Numpy, Pandas, and Matplotlib </span>\n",
    "\n",
    ">Jupyter Notebook: **'Arrays, dataframes & plotting with Python'**\n",
    "\n",
    ">Goal: first steps with Numpy, Matplotlib & Pandas\n",
    "\n",
    ">By: H.J. Megens\n",
    "\n",
    ">Where you can reach me: hendrik-jan.megens -at- wur.nl\n",
    "\n",
    ">Last modified: 26 September 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays and basic Numpy\n",
    "\n",
    "Arrays are one-dimensional (vectors), two-dimensional, or multidimensional datastructures that hold data. One characteristic of arrays is that they only hold one type of data (usually numerical, either int or float, but strings work too). Numpy has a specialized package for working with numerical array data, called Numpy. Numpy is extremely efficient in working with numerical data and has many built-in methods for mathematical operations. Numpy is one of the major reasons Python has become very important in the 'Data Analytics' wave, also known as 'Big Data' revolution, and sometimes referred to as 'machine learning'. Here you will briefly explore a few characteristics of Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic properties of vectors and arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell #1\n",
    "# First we import the numpy module\n",
    "import numpy as np # accepted convention of importing numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #2\n",
    "# How to make a numpy array ...\n",
    "# ... or rather a 1-dim vector\n",
    "a = np.array([1,2,3])\n",
    "print(a)  # see what it contains\n",
    "print(a.dtype) # see what datatype the array is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #3\n",
    "# an another one...\n",
    "b = np.array([4,5,6])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #4\n",
    "# doing simple mathematical operations is easy-peasy.\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #5\n",
    "# Just note how different this behavior is from working with normal lists:\n",
    "a_list = [1,2,3]\n",
    "b_list = [4,5,6]\n",
    "a_list + b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell #6\n",
    "# Concatenating matrices or vectors\n",
    "# This is an example of a so-called 'vertical-stack'\n",
    "# Other options are 'hstack' - horizontal - and 'dstack'\n",
    "c = np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #7\n",
    "# show contents of c\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #8\n",
    "# get the value of the first row, and second column\n",
    "c[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #9\n",
    "# Notice the difference between retrieving elements from\n",
    "# simple lists in simple lists\n",
    "c_list = [[1,2,3],[4,5,6]]\n",
    "# In this case you need to go 'one deeper' into the list\n",
    "c_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell #10\n",
    "# various mathematical operations can be applied to matrices\n",
    "# for instance squaring\n",
    "d = c**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #11\n",
    "# d is again a 3x2 array, now containing the squared values of c\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #12\n",
    "# 'd' is a numpy array object, which has several built-in methods, such\n",
    "# as summing the values\n",
    "d.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #13\n",
    "# larger then?\n",
    "d > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #14\n",
    "# You can change values in an array\n",
    "d[0,1] = 21\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #15\n",
    "# Which ones now larger than 20?\n",
    "d > 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting elements from arrays based on logic values - True or False?\n",
    "\n",
    "Assume you would like to slice a list based on an arbitrary list that simply states 'select yes-or-no'. You could try something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell #16\n",
    "\n",
    "mylist = ['a','b','c','d']\n",
    "my_logic_list = [False,True,True,False]\n",
    "mylist[my_logic_vector]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but that doesn't work for the standard Python lists, in fact the only way to extract locations from a string or list is to use slices. In this case, because the elements we want to extract are adjacent, we could do the following, but in case the elements you want to select are not adjacent, that won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17\n",
    "mylist[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numpy arrays/vectors, you can select an arbitrary selection of elements, based on supplying a vector (or array) of similar dimensions that contains Booleans `True` or `False` in the order of elements to be selected, or not selected. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18\n",
    "myvec = np.array(['a','b','c','d'])\n",
    "my_logic_vector = np.array([False,True,True,False])\n",
    "myvec[my_logic_vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to note, Numpy arrays can be transformed to standard Python lists, and vice versa. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19\n",
    "selection = list(myvec[my_logic_vector])\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wonder: \"So what?\". What's so great about this type of selecting elements in a vector or array. Well, consider this example, where you might be interested in selecting only the numbers in the array that are larger than 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20\n",
    "myvec = np.array([10, 5.0, 7, 15])\n",
    "myvec > 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above results in an array, of data type Boolean. First and last elements are indeed larger than 8, the two middle ones are not. This Boolean array can subsequently be passed back into the original array (or vector) to then only show the elements that are `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21\n",
    "myvec[myvec>8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all elements are of type float. You can't mix types in a Numpy array, we'll come back to that in the section 'Dataframes'. \n",
    "\n",
    "You can also construct composite logical expressions, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22\n",
    "myvec[(myvec > 8) & (myvec < 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, this works because of the Boolean vector created by the two tests: number larger than 8 `AND` smaller than 12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23\n",
    "(myvec > 8) & (myvec < 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Getting Familiar With Numpy #\n",
    "\n",
    "**Learning goals:**\n",
    "* Familiarize yourself with Numpy, and how to apply internal functions (methods)\n",
    "* Understand array coordinates\n",
    "\n",
    "\n",
    "**a)** Create a numpy array ‘x’, based on the following list:\n",
    "\n",
    "**`[[67,98,202],[43,2,6],[12,99,100]]`**\n",
    "\n",
    "Have a look at Cells #2 and #3 for basic syntax. \n",
    "Produce the square of the matrix (name **`x_square`**). Look at cell #10 for basic syntax. What is the value in row 3, column 2? Cell #8 (a.o.) shows basic syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** multiply the array using the vector '**`a`**' from the Notebook and call that matrix '**`a_x`**'. In which ‘direction’ does the multiplication occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** By applying '`dir(a_x)`' you can find out which methods can be applied to your array. Calculate **sum**, **mean**, **standard deviation**, **minimum value** and **maximum value** of the matrix. See cell #14 for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Create a truth table (array with True and False) for values larger than 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Then, use that truth table to retrieve all values of '**`a_x`**' larger than 200. Cells #21 and #22 provide further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: The *Iris* dataset\n",
    "\n",
    "**Learning goals:**\n",
    "* Learn how to understand data structures and their features\n",
    "* Learn how to use (Boolean) vectors or arrays to subset other arrays.\n",
    "\n",
    "![iris species](iris_species.jpg)\n",
    "The *Iris* dataset is one of the classic biological datasets, created by the famous geneticist R.A. Fisher. The data is derived from measurements on flowers of three *Iris* species: *I. versicolor*, *I. setosa*, and *I. virginica*. The dataset contains four measurements per flower: sepal length and width, and petal length and width.\n",
    "\n",
    "![Iris flower](Iris_flower.jpg)\n",
    "\n",
    "The data set is often used to demonstrate or benchmark machine-learning techniques. For more information on the *Iris* dataset, visit the <a href=https://en.wikipedia.org/wiki/Iris_flower_data_set>Wikipedia page</a>.\n",
    "\n",
    "Because the *Iris* data set is small, and often used for demonstrating machine learning techniques, it is often bundled in analytical packages for languages often used in data science, such as R and Python. In Python, the most used package for machine learning is the Scikit-learn package. \n",
    "\n",
    "We will first load the dataset and explore some of its properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # import numpy\n",
    "from sklearn import datasets # import the 'datasets' \n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Learn data packages have a specific structure which you don't need to remember. However, you can always use the `dir()` function on any object to investigate which methods are available. For now, we will focus on the `.keys()` method, which tells us that the datastructure is a bit like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the different 'items' in the data package. Let's explore them. One is called 'DESCR', and hold a description of the data package. Curious what it has to say? Just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the absence of parenthesis, because iris.DESCR is a data structure, not a method (function built-in the method).\n",
    "\n",
    "This is a nice overview of the data. The data is derived from three species of *Iris*: *I. setosa*, *I.versicolor*, and *I. virginica*. These names can also be found in the `iris.target_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 150 flowers were measured, 50 for every species. The order of the species in the actual data array is given by the `iris.target` vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** What species do the 0's, 1's and 2's correspond to, respectively? How can you subset the `iris.target_names` vector to extract the name 'setosa'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structures of the flowers that were measured are called 'features'. Their names too can be retrieved from `iris`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual measurements are found in the `iris.data` datastructure. The first ten rows of the iris data show the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next questions you will explore some of the features of `iris.data`. \n",
    "\n",
    "**b)** What kind of data structure is `iris.data`? Use both the general Python `type()` function, as well as the iris.data specific `dtype` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris.data object has, like any python object, methods (object-specific functions), which  require parentheses (just like regular functions), but also has attributes, which hold information specific to the object. Both methods and attributes can be listed by doing `iris.data.<TAB>`, which will autocomplete, and in the notebook will bring forward a list of all methods and attributes. \n",
    "\n",
    "**c)** Can you find an attribute or method that will tell you the 'shape' of the data matrix? Not sure if the likely name is a method or attribute? Just try. If you invoke it without parentheses and it gives an error, it is likely a method. In addition, you can always use the '?' after the name for more information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of iris.data holds the measurments of the sepal length. You can extract the first column in this way:\n",
    "```Python\n",
    "iris.data[:,0]\n",
    "```\n",
    "The ':' (colon) is a slice from start to end. Since it is the first index value, this means: \"all rows\". The '0' stands for the first column, since it is the second index value.\n",
    "\n",
    "**d)** Capture the first column in a variable called `sepal_length`. What type is `sepal_length`? What is its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** The `sepal_length` object that you've made has a number of attributes. Find the methods to calculate mean and standard deviation, and calculate these values. Check if the values are the same as in the description of the iris data package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation you have just calculated was based on all three species. We might want to do the same for each of the species. Let's brake that down first in a number of steps. Say we want to do this first for one species, versicolor. This species is the second in the `iris.target_names` vector, and therefore has index value `1`, both in the `iris.target_names` and corresponding `iris.target` vectors. \n",
    "\n",
    "**f)** Create a Boolean vector called `is_versicolor` based on iris.target by asking when iris.target is 1. \n",
    "```Python\n",
    "iris.target == 1\n",
    "```\n",
    "How long is the Boolean vector? Which values does it contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** Create a vector, called `versicolor_sepal_length`, that has *only* the versicolor sepal length information. This means you have to get the first column from `iris.data`, and then subset that vector based on the Boolean vector `is_versicolor` created in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make use of the realization that once you know how to do something for one thing, you can do it for all. Automation! Looping! (Remember! Laziness is a virtue! Or at least, it *can* be...)\n",
    "\n",
    "**h)** Make a for loop where you will calculate mean and std for every one of the three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with Matplotlib\n",
    "### Task 3: A very short primer on Matplotlib\n",
    "\n",
    "**Learning goals:**\n",
    "* Explore plotting with Python, particularly with the Matplotlib library\n",
    "* Familiarize yourself with a few basic plotting types, and basic elements of a plot\n",
    "* Learn to set up basic plots, and then extending them by adding more elements.\n",
    "\n",
    "In this section we will explore a few basic properties of Matplotlib and demonstrate how you can make nice figures by just a limited number of lines of code. One of the added learning goals is to explore the extensibility of the Matplotlib code. By adding figure titles, legends, axis labels, and by modifying color and other features of plotted lines and dots, you can make beautiful, publishing grade figures tailored to your needs, and, importantly, automate it without much additional effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first demonstration will be on a well-known mathematical operation: taking the sine and cosine of a bunch of values, and then plot the x and y values. For this we first need to have a vector of 'x-coordinates'. Numpy has a neat little function for that, called 'linspace'. The next line of code will produce 100 values between zero and ten, evenly spaced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib supports different coding styles. This can become a bit confusing, so we will only show one today, which is also the one that is most often used. It is in line with the 'Matlab' way of plotting. This is not surprising as <a href=https://en.wikipedia.org/wiki/MATLAB>Matlab</a> has inspired the Python Matplotlib makers. There is also a more 'Pythonesque' way of doing it, which has a number of advantages, but you will see that slightly less often in coding examples (although Matplotlib developers appear to <a href=http://matplotlib.org/faq/usage_faq.html#coding-styles>encourage the object, Python way</a>).\n",
    "\n",
    "The general procedure is as follows: open an 'active' figure. This is usually not strictly necessary in Matlab style, but has a few advantages. First, it explicitly delineates the active plot. And second it allows to modify canvas properties. After activating a canvas, you can add a number of plotting statements, and add other features. After all the elements are added to the active plot, you can display it (or write it to a file).\n",
    "\n",
    "**a)** In the first exercise you will add more features. You can do this by removing the `#` in front of a line of code, or swapping out lines. Eacht time, run the cell, and see what changes. Note also the syntax to define line style and color. 'b' is blue, 'g' is green, and 'r' is red. There are many more. What does '--' do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "plt.figure() # create figure\n",
    "\n",
    "plt.plot(x,np.sin(x)) # basic plotting function\n",
    "plt.plot(x,np.cos(x)) # basic plotting function\n",
    "# replace these two lines by:\n",
    "# plt.plot(x,np.sin(x), 'r')   # you can modify colors\n",
    "# plt.plot(x,np.cos(x), '--b') # and line patterns\n",
    "# and then replace these in turn by:\n",
    "# plt.plot(x,np.sin(x), 'b',label = 'sin') # 'label' is shown by plt.legend()\n",
    "# plt.plot(x,np.cos(x), '--g', label = 'cos') # 'label' is shown by plt.legend()\n",
    "\n",
    "# Then, one by one, add these lines. Observe and report differences.\n",
    "# plt.xlim((-1,11))       # change the default limits of the plot, horizontal direction\n",
    "# plt.ylim((-1.2,1.2))    # change the default limits of the plot, vertical direction\n",
    "# plt.title('This is my title') # add a title to the plot\n",
    "# plt.xlabel('X')  # add label for x-axis\n",
    "# plt.ylabel('Y')  # add label for y-axis\n",
    "# plt.legend() # when activating this, make sure that 'label' is added to plot function!\n",
    "plt.show() # finally: display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key concepts of this plotting style is the 'active plotting window' where you can add and modify stuff until you decide to plot. Within a plot you can also add subplots, for instance if you would like to plot the sine and cosine functions in separed graphs. The same principle then holds. Here we demonstrate plotting using different subplots.\n",
    "\n",
    "**b)** For each subplot, add a title, saying either 'sin' or 'cos'. For syntax how to plot a title, see the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "x = np.linspace(0,10,100)\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)      # subplot: two rows, one column, 1st plot\n",
    "plt.plot(x,np.sin(x))\n",
    "plt.subplot(2,1,2)      # subplot: two rows, one column, 2nd plot\n",
    "plt.plot(x,np.cos(x), '--g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Change the layout of the plot, stacking the sine and cosine plots vertically in stead of horizontally as in the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "x = np.linspace(0,10,100)\n",
    "plt.figure()\n",
    "# plt.subplot(?)        # modify this line of code and uncomment it\n",
    "plt.plot(x,np.sin(x))\n",
    "# plt.subplot(?)        # modify this line of code and uncomment it\n",
    "plt.plot(x,np.cos(x), '--g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Plotting the Iris data\n",
    "\n",
    "**Learning goals:**\n",
    "* Learn to integrate complex data structures in a plotting strategy\n",
    "* Learn to tinker with code to make attractive plots\n",
    "\n",
    "For a more meaningful example, we will explore the *Iris* dataset again. First order of business: import the libraries we will use in this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # matplotlib\n",
    "%matplotlib inline              \n",
    "                                 # Jupyter notebook specific 'magic' - figures\n",
    "                                 # will be plotted in the notebook.\n",
    "\n",
    "import numpy as np               # numpy\n",
    "from sklearn import datasets     # import the 'datasets' \n",
    "iris = datasets.load_iris()      # load the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example makes a `scatterplot` of the Iris data: Sepal Lenght vs Sepal Width. Again, the plot is initialized, a plot statement is made (in this case 'scatter'), using first and second columns of the `iris.data` array. Then a title is added.\n",
    "\n",
    "**a)** Modify the code below so that x-axis and y-axis labels are plotted ('Sepal Lenght', 'Sepal Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "plt.figure()\n",
    "plt.scatter(iris.data[:,0],iris.data[:,1])\n",
    "plt.title('Iris data: Sepal Length vs Sepal Width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to make a plot of all Iris samples, you can actually take your solution for Task 2, question h, to sequentially plot the data for the three different species. As you sequentially invoke a plot statement for each species separately, you can modify, for instance, the 'label', which is important for the legend. But also the color of the dots (or anything else if you want; don't hesitate to experiment).\n",
    "\n",
    "**b)** Replace the '?' with the correct variable/vector so that it works. Question: how are label names and dot color dynamically modified?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "colors = ['blue','red','green']\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    sepal_length = iris.data[:,0][iris.target==i]\n",
    "    sepal_width = iris.data[:,1][iris.target==i]\n",
    "    plt.scatter('?','?', label = iris.target_names[i], c=colors[i] ) # replace '?'\n",
    "plt.title('Iris data: Sepal Length vs Sepal Width')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen 'plot' and 'scatter' functions. There are many other [plotting functions](https://matplotlib.org/api/pyplot_summary.html), such as the 'bar', 'boxplot', and 'histogram'. There is no time to explore them all. One we will explore for the Iris data is the histogram. One of the interesting features of the *Iris* data set is that you can not distinghuis the three species on any single character alone. Every feature has a distribion which overlaps with another species. Let's explore the distribution of 'Sepal Length' for I. versicolor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of sepal lengths.\n",
    "plt.figure()\n",
    "plt.hist(iris.data[iris.target ==1,0], color='blue', alpha = 0.9, label = 'versicolor')\n",
    "plt.title('Iris data, histogram of Sepal Length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Now add one line, similar to the second line of code in the previous cell, so that you add *I. setosa* to this plot. Make sure you have appropriate species and column from the iris.data array! And modify the line so that 'label' and color are changed, maybe change it to red? **Also note the 'alpha' parameter. You can set it to a value between 0 and 1**. It changes the transparancy. **Play** with it a bit to create a histogram that you like most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "plt.figure()\n",
    "plt.hist(iris.data[iris.target ==1,0], color='blue', alpha = 0.9, label = 'versicolor')\n",
    "# ADD LINE OF CODE HERE\n",
    "\n",
    "plt.title('Iris data, histogram of Sepal Length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes \n",
    "### Task 5: A short primer on Dataframes using Pandas\n",
    "\n",
    "**Learning goals:**\n",
    "* Understand the properties of a data frame, and how that differs from an array\n",
    "* Explore the power of Pandas for numerical data manipulation and analysis\n",
    "\n",
    "Arrays and vectors are incredibly powerful structures for numerical data analysis. In some languages, such as R, arrays and vectors are primary data types, which in large part explains the appeal of R for statistical data analysis - well, in fact that language has numerical data analysis as primary focus. Numpy has done much the same for Python, and Python for instance is quite popular in physics research and there is a trend that Python is replacing other languages/programming environments, such as Matlab.\n",
    "\n",
    "Arrays and vectors, however, also show a fundamental limitation: they can only hold a single data type, and that data type is usually numerical. consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['some random string', 1, 0.3]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_list` is a list that holds three elements, each of different type: a string, integer, and float. Now consider what happens next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays always have a single type. Since one of the elements from the list is a string, that requires the rest to be of type string as well, because a string can not be converted (meaningfully) to a numerical value.\n",
    "\n",
    "When we supply a list of integers, on the other hand, a numpy array of type integer can be made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list= [1,1,1]\n",
    "my_vector = np.array(my_list)\n",
    "print my_vector.dtype \n",
    "my_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default integers in Python take 64 bits. If you have many integers in an array, say hundreds of millions, but each of the integers is small (smaller than 256, in fact), you can get away with explicitly converting to 8-bit integers. This saves 8 times the memory. This is important for working with bit-mapped pictures, but can also be relevant for DNA data, if you code your bases simply 0,1,2,3.\n",
    "\n",
    "Now, again, numpy arrays can only have a single type, so when all values are numerical, but not all are integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_list= [1.0,1,1]\n",
    "my_vector = np.array(my_list)\n",
    "print my_vector.dtype\n",
    "my_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, arrays and vectors don't allow you to mix data types, but lists do. \n",
    "\n",
    "In practise, many of the data sets we are likely to encounter are organized in a column-separated fashion ('tables'), ie. have a 'matrix-like' lay-out, which could make them suitable for manipulation and computation in arrays. However, tables often have a mix of data types. Our Crane data set is a good case in point. To accomodate this type of dataset, you need to use the Data Frame. If that sounds arcane, it shouldn't. There is no doubt you have worked with data frames before. Just think of 'Excel sheets'.\n",
    "\n",
    "Data frames are usually organized as a collection of named vectors or lists. Each column represents one data type, that holds for instance integers, and which has a name attached to it seperately which can be a string. Different columns can have different data types, such as string or float, but within each column, the data type is the same, allowing for optimal efficiency of working with the data per column. \n",
    "\n",
    "Data frames, like arrays, although internally always of compounded types, are basic data structures in some languages, such as R and Matlab. In Python too, it was recognized that with the Numpy and SciPy modules in place and very popular, there was a need to support dataframes. For this purpose the Pandas module was created. \n",
    "\n",
    "Like dataframes in other languages, the Pandas dataframe supports slicing and indexing, although the syntax to do that requires a bit of practice. However the same holds for languages like R, and, in fact, the dataframe syntax of Pandas is quite similar, although there are some quirks (although it can be argued that these quirks make the Pandas dataframe more easily sliceable than the R dataframes). Since the Pandas dataframe internally consists of Numpy vectors, all the mathematics tools and efficiency that people have come to love in Numpy are built into Pandas as well.\n",
    "\n",
    "Let's start this part on Pandas with the Iris dataset, but now, instead of getting it from a built-in package, we'll load it directly from an excel sheet. \n",
    "\n",
    "*Caveat emptor: like with every strategy where you want to load an entire datastructure into memory, this could go south quite significantly if your dataset is huge. Like, seriously crashing your computer. So pay attention to the size of your input data. There are some interesting 'Out of Memory' solutions that are compatible with Pandas to deal with very large arrays, such as hdf5-based arrays, but these are several parsecs beyond the scope of this practical.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # the most accepted way of importing the pandas package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Explore the `pd` object. Find a method/function that can load the `Iris.xlsx` data into a dataframe with variable name `iris_pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a\n",
    "iris_pd = pd.<METHOD>('Iris.xlsx') # apply appropriate method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Now that you have loaded the Iris data into the `iris_pd` dataframe, the `iris_pd` object has Pandas-specific methods that allow you to do things with it. One of the things is to show just the first lines of the table, much like the 'head' command in the shell. Explore your `iris_pd` dataframe for a method that might do just that, and apply it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with arrays, it is very easy to retrieve a single column of data. To extract the column that holds the sepal length measurements, you simply do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_sepal_length_pd = iris_pd['sepal length (cm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that the syntax is very similar to extracting a value from a dictionary by supplying a key to the dictionary. That is not a co-incidence: the Pandas dataframe organizes the different columns very much like items in a dictionary. \n",
    "\n",
    "**c)** Explore properties of the `iris_sepal_length_pd` object. What type is it? Can you determine its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Calculate mean and std of sepal length. See if there are methods in the object that can do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract rows, use loc (or iloc). The loc method works similar for selecting values as you saw earlier in Numpy arrays. There is one difference: you can use (lists of) column names as keys (for rows too, if you have named rows, which we don't have here). But you can also use index values, which can be a slice, a numpy array with row numbers, or Boolean vector.\n",
    "```Python\n",
    "iris_pd.loc[?,['species','sepal length (cm)','sepal width (cm)']]\n",
    "```\n",
    "\n",
    "Where the '?' is a placeholder for the rows to select. \n",
    "\n",
    "**e)** Replace the '?' with a 'slice' that returns the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n",
    "iris_pd.loc['?',['species','sepal length (cm)','sepal width (cm)']] # replace '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Replace the '?' with a numpy array with values to retrieve only lines 1,3,5,141 and 142 in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\n",
    "iris_pd.loc['?',['species','sepal length (cm)','sepal width (cm)']] # replace '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** To extract only the *I. setosa* samples from the data frame, replace the index in the previous cell with a Boolean vector (or, in this case, Pandas series), based on this statement:\n",
    "```Python\n",
    "iris_pd['species'] == 'setosa'\n",
    "```\n",
    "As usual, if you don't quite understand each step, break it down. You can always catch any outcome of code (well, if it returns an object), in a variable and explore it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g\n",
    "iris_pd.loc['?','sepal length (cm)'] # replace '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a little demonstration of adding a column. We can calculate the ratio between sepal sength and sepal width and store it in an additional column, called 'ratio':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_pd['ratio'] = iris_pd['sepal length (cm)']/iris_pd['sepal width (cm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h)** Show the first 10 lines of the data frame, and show the dimensions ('shape'). What has changed? Is this an 'in-place' addition, i.e. can a data frame be changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "*Final note on Pandas: Pandas does have a built-in library for plotting. However, since there is already much that will be confusing even dealing with just one plotting method (and, as mentioned, even Matplotlib has already 2!) I don't want to bother you with it here. Furthermore, Matplotlibs options are far more extensive, and all the Pandas datastructures are compatible with Matplotlib anyway. *\n",
    "\n",
    "## Further reading:\n",
    "- [matplotlib website](https://matplotlib.org/)\n",
    "- [matplotlib examples](https://matplotlib.org/gallery.html)\n",
    "- [Pandas](http://pandas.pydata.org/)\n",
    "- [Python data science handbook (O'Reilly) - recommended](http://a.co/2jL2pqf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
